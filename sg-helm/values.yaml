# Currently tested with Kubernetes 1.10 on AWS EKS and Minkube
common:
  
  #namespace, separate logs from data
  #logdriver, ???
  #separate http certificates
  
  cluster_name: "searchguard"
  elkversion: "6.5.4"
  sgversion: "24.0"
  sgkibanaversion: "17"
  xpack_basic: true
  allow_democertificates: true

  # NOT FREE FOR COMMERCIAL USE
  sg_enterprise_modules_enabled: true

  # Defines the service type for all outward-facing (non-discovery) services.
  serviceType: ClusterIP
  #serviceType: NodePort
  #serviceType: LoadBalancer

  # Any extra or specific configuration that is needed can be added here.
  # Will be added to all elasticsearch.yml files on all nodes
  config:   
    #http:
    #  compression: false
    #  cors:
    #    enabled: false
    #    allow-origin: "*"
    #index.codec: best_compression

  # If you want any plugins installed, give them here as a list. They will be
  # passed to elasticsearch-plugin install -b {line here}
  # Do not add the searchguard plugin here, because its already installed in the main image
  plugins:
    - analysis-phonetic

# Client/ingest nodes can execute pre-processing pipelines, composed of
# one or more ingest processors. Depending on the type of operations performed
# by the ingest processors and the required resources, it may make sense to
# have dedicated ingest nodes, that will only perform this specific task.
client:
  # It isn't common to need more than 2 client nodes.
  replicas: 1
  antiAffinity: "soft"
  heapSize: 1g
  # More info on what this setting does is in the config map. Only change this
  # if you set the cpu limit to over 1 full cpu.
  processors: 1
  labels: {}
  annotations: {}
  resources:
    limits:
      cpu: 500m
      memory: 1500Mi
    requests:
      cpu: 100m
      memory: 1500Mi

# Data nodes hold the shards that contain the documents you have indexed. Data
# nodes handle data related operations like CRUD, search, and aggregations.
# These operations are I/O-, memory-, and CPU-intensive. It is important to
# monitor these resources and to add more data nodes if they are overloaded.
#
# The main benefit of having dedicated data nodes is the separation of the
# master and data roles.
data:
  # This count will depend on your data and computation needs.
  replicas: 1
  antiAffinity: "soft"
  storage: 4Gi
  storageClass: "standard"
  heapSize: 1g
  # More info on what this setting does is in the config map. Only change this
  # if you set the cpu limit to over 1 full cpu.
  processors: 1
  labels: {}
  annotations: {}
  resources:
    limits:
      cpu: 1
      memory: 1500Mi
    requests:
      cpu: 1
      memory: 1500Mi

# The master node is responsible for lightweight cluster-wide actions such as
# creating or deleting an index, tracking which nodes are part of the
# cluster, and deciding which shards to allocate to which nodes. It is
# important for cluster health to have a stable master node.
master:
  # Master replica count should be (#clients / 2) + 1, and generally at least 3.
  replicas: 1
  antiAffinity: "soft"
  storage: 2Gi
  storageClass: "standard"
  heapSize: 1g
  # More info on what this setting does is in the config map. Only change this
  # if you set the cpu limit to over 1 full cpu.
  processors: 1
  labels: {}
  annotations: {}
  resources:
    limits:
      cpu: 500m
      memory: 1500Mi
    requests:
      cpu: 100m
      memory: 1500Mi

kibana:
  httpPort: 5601
  replicas: 1
  #serviceType: ClusterIP
  #serviceType: NodePort
  serviceType: LoadBalancer
  labels: {}
  annotations: {}
  resources:
    limits:
      cpu: 500m
      memory: 2500Mi
    requests:
      cpu: 100m
      memory: 2500Mi


service:
  httpPort: 9200
  transportPort: 9300

# Kubernetes Role-based access control
# https://kubernetes.io/docs/reference/access-authn-authz/rbac/
rbac:
  create: true

pullPolicy: IfNotPresent
  
