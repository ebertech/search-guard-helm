# Currently tested with Kubernetes 1.10 on AWS EKS 

common:
  image:
    repository: floragunncom/sg-elasticsearch
    tag: "6.5.3-oss-23.2"
    pullPolicy: IfNotPresent

  # Defines the service type for all outward-facing (non-discovery) services.
  serviceType: ClusterIP
  #serviceType: NodePort
  #serviceType: LoadBalancer
  # Any extra or specific configuration that is needed can be added here.
  config:
    index.codec: best_compression
  # If you want any plugins installed, give them here as a list. They will be
  # passed to elasticsearch-plugin install -b {line here}
  # Do not add the searchguard plugin here, because its already installed in the main image
  plugins:
    #- analysis-phonetic

  env:
    CLUSTER_NAME: "searchguard-demo"
    #NETWORK_HOST: "_eth0_"
    NETWORK_HOST: "0.0.0.0"
    # see https://discuss.elastic.co/t/bootstrap-checks-failed-due-to-memory-is-not-locked/89178/3
    # TODO: enable memory lock
    MEMORY_LOCK: "false"
    HTTP_CORS_ENABLE: "false"
    ALLOW_DEMOCERTIFICATES: "true"
    # The minimum number of masters that will be able to form a quorum. This
    # should be (#masters / 2) + 1. Default is 2.
    NUMBER_OF_MASTERS: "1"

# Client/ingest nodes can execute pre-processing pipelines, composed of
# one or more ingest processors. Depending on the type of operations performed
# by the ingest processors and the required resources, it may make sense to
# have dedicated ingest nodes, that will only perform this specific task.
client:
  # It isn't common to need more than 2 client nodes.
  replicas: 1
  antiAffinity: "soft"
  heapSize: 1g
  # More info on what this setting does is in the config map. Only change this
  # if you set the cpu limit to over 1 full cpu.
  processors: 1
  labels:
  annotations:
  resources:
    limits:
      cpu: 500m
      memory: 1500Mi
    requests:
      cpu: 100m
      memory: 1500Mi

# Data nodes hold the shards that contain the documents you have indexed. Data
# nodes handle data related operations like CRUD, search, and aggregations.
# These operations are I/O-, memory-, and CPU-intensive. It is important to
# monitor these resources and to add more data nodes if they are overloaded.
#
# The main benefit of having dedicated data nodes is the separation of the
# master and data roles.
data:
  # This count will depend on your data and computation needs.
  replicas: 1
  antiAffinity: "soft"
  storage: 12Gi
  storageClass: "standard"
  heapSize: 1g
  enableHTTP: false
  # More info on what this setting does is in the config map. Only change this
  # if you set the cpu limit to over 1 full cpu.
  processors: 1
  labels:
  annotations:
  resources:
    limits:
      cpu: 1
      memory: 1500Mi
    requests:
      cpu: 1
      memory: 1500Mi

# The master node is responsible for lightweight cluster-wide actions such as
# creating or deleting an index, tracking which nodes are part of the
# cluster, and deciding which shards to allocate to which nodes. It is
# important for cluster health to have a stable master node.
master:
  # Master replica count should be (#clients / 2) + 1, and generally at least 3.
  replicas: 1
  antiAffinity: "soft"
  storage: 2Gi
  storageClass: "standard"
  heapSize: 1g
  enableHTTP: false
  # More info on what this setting does is in the config map. Only change this
  # if you set the cpu limit to over 1 full cpu.
  processors: 1
  labels:
  annotations:
  resources:
    limits:
      cpu: 500m
      memory: 1500Mi
    requests:
      cpu: 100m
      memory: 1500Mi

service:
  httpPort: 9200
  transportPort: 9300

# Kubernetes Role-based access control
# https://kubernetes.io/docs/reference/access-authn-authz/rbac/
rbac:
  create: true
  
kibana:
  image:
    repository: floragunncom/sg-kibana
    tag: "6.5.3-oss-16"
    pullPolicy: Always
  httpPort: 5601
  replicas: 1
  serviceType: ClusterIP
  #serviceType: NodePort
  #serviceType: LoadBalancer
  resources:
    limits:
      cpu: 500m
      memory: 1500Mi
    requests:
      cpu: 100m
      memory: 1500Mi
